## Monday
- made the first draft for the ispa poster took most of the day
- purchased the rest of the travel items like the hotel
- sent out reciepts to everyone who needed them

## Tuesday
- started really working on figuring oout what i will be doing for the next stint of this project
- i did a literature review today and would add stuff to the paper i am working on for this project
- i read this article on the new xlstm architecture https://medium.com/@zergtant/deep-dive-into-xlstm-the-evolution-of-lstm-architecture-and-pytorch-code-implementation-d901a14bbcec
- i think that currently the xlstm architecture may yield to be valuable to have in the context of what we are working the residual block that prevend  gradienct explosion although are designed for being abhle to make the model deeper thy will probably yield valuue for us too.
- i realized that part of my data is incorrectly structured so i am going to fix that
- it took a lot of work but i got the dataset corrsectly shaped for the lstm training
- 

## Wednesday

## Thursday


## Friday 


## Saturday 

## Sunday


## TODO
- clean up and organize the dataset creation notebook
- add more to documentation
- clean up documentation
- fix the poster 
- send the poster off to get printed
- send mary the reciept for the poster
- get what size mary is for her hoodie - medium
- with the lstm model i want to try training a few batches one on the season leading up to the cases
- try training on unaggergated data
- try trainning on aggregated data
- train using dropout and without dropout
- add data augmentation to it to see if it changet the models performance the reason i want to do this is because the xlstm architecture worskt best on large datasets





https://github.com/AI-Guru/xlstm-resources?tab=readme-ov-file

