{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original shape of vf: (1410, 4), The original shape of wf: (19241397, 28)\n"
     ]
    }
   ],
   "source": [
    "# valley fever data\n",
    "vf = pd.read_excel('../../data/original_datasets/ValleyFeverDashboard_Data.xlsx')\n",
    "# weather data\n",
    "wf = pd.read_csv('../../data/original_datasets/weather_data_original.csv')\n",
    "\n",
    "print(f'The original shape of vf: {vf.shape}, The original shape of wf: {wf.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1056, 3)\n",
      "48\n",
      "['Alameda' 'Amador' 'Berkeley' 'Butte' 'Calaveras' 'Colusa' 'ContraCosta'\n",
      " 'ElDorado' 'Fresno' 'Humboldt' 'Imperial' 'Kern' 'Kings' 'Lassen'\n",
      " 'LongBeach' 'Madera' 'Marin' 'Mendocino' 'Merced' 'Monterey' 'Napa'\n",
      " 'Nevada' 'Orange' 'Pasadena' 'Placer' 'Riverside' 'Sacramento'\n",
      " 'SanBenito' 'SanBernardino' 'SanDiego' 'SanFrancisco' 'SanJoaquin'\n",
      " 'SanLuisObispo' 'SanMateo' 'SantaBarbara' 'SantaClara' 'SantaCruz'\n",
      " 'Siskiyou' 'Solano' 'Sonoma' 'Stanislaus' 'Sutter' 'Tehama' 'Tulare'\n",
      " 'Tuolumne' 'Ventura' 'Yolo' 'Yuba']\n"
     ]
    }
   ],
   "source": [
    "# rename columns\n",
    "vf = vf.rename(columns={\n",
    "    'Valley Fever Cases and Incidence Rates by Local Health Jurisdiction, California, 2001-2022 ' : 'County',\n",
    "    'Unnamed: 1' : 'Year',\n",
    "    'Unnamed: 2' : 'Cases', \n",
    "    'Unnamed: 3' : 'Rate'\n",
    "})\n",
    "\n",
    "# remove unuseful info\n",
    "vf.drop(index=vf.index[0],axis=0,inplace=True)\n",
    "vf.drop(index=vf.index[-1],axis=0,inplace=True)\n",
    "vf.drop('Rate', axis=1, inplace=True) \n",
    "\n",
    "#change dtypes\n",
    "\n",
    "vf['Year'] = pd.to_datetime(vf['Year'], format='%Y')\n",
    "vf['Year'] = vf['Year'].dt.year\n",
    "vf['Cases'] = pd.to_numeric(vf['Cases'])\n",
    "\n",
    "#remove counties from vf where there are less than 60 cases or it is a total of multiple counies \n",
    "counties_to_drop = [\"ALPINE\", \"DEL NORTE\", \"GLENN\", \"INYO\", \"LAKE\", \"MARIPOSA\", \"MODOC\", \"MONO\", \"PLUMAS\", \"SHASTA\", \"SIERRA\", \"TRINITY\", \"LOS ANGELES\", 'ALAMEDA COUNTY TOTAL', 'CALIFORNIA TOTAL', 'LOS ANGELES COUNTY TOTAL']\n",
    "vf = vf.drop(vf[vf['County'].isin(counties_to_drop)].index, axis=0)\n",
    "print(vf.shape)\n",
    "print(len(vf[\"County\"].unique()))\n",
    "\n",
    "# relabel all of the counties so it is in a better format\n",
    "vf['County'] = vf['County'].replace({\n",
    "    'ALAMEDA': 'Alameda',\n",
    "    'AMADOR': 'Amador',\n",
    "    'BERKELEY': 'Berkeley',\n",
    "    'BUTTE': 'Butte',\n",
    "    'CALAVERAS': 'Calaveras',\n",
    "    'COLUSA': 'Colusa',\n",
    "    'CONTRA COSTA': 'ContraCosta',\n",
    "    'EL DORADO': 'ElDorado',\n",
    "    'FRESNO': 'Fresno',\n",
    "    'HUMBOLDT': 'Humboldt',\n",
    "    'IMPERIAL': 'Imperial',\n",
    "    'KERN': 'Kern',\n",
    "    'LASSEN': 'Lassen',\n",
    "    'LONG BEACH': 'LongBeach',\n",
    "    'MADERA': 'Madera',\n",
    "    'MARIN': 'Marin',\n",
    "    'MENDOCINO': 'Mendocino',\n",
    "    'MERCED': 'Merced',\n",
    "    'MONTEREY': 'Monterey',\n",
    "    'NAPA': 'Napa',\n",
    "    'NEVADA': 'Nevada',\n",
    "    'ORANGE': 'Orange',\n",
    "    'PASADENA': 'Pasadena',\n",
    "    'PLACER': 'Placer',\n",
    "    'RIVERSIDE': 'Riverside',\n",
    "    'SACRAMENTO': 'Sacramento',\n",
    "    'SAN BENITO': 'SanBenito',\n",
    "    'SAN BERNARDINO': 'SanBernardino',\n",
    "    'SAN DIEGO': 'SanDiego',\n",
    "    'SAN FRANCISCO': 'SanFrancisco',\n",
    "    'SAN JOAQUIN': 'SanJoaquin',\n",
    "    'SAN LUIS OBISPO': 'SanLuisObispo',\n",
    "    'SAN MATEO': 'SanMateo',\n",
    "    'SANTA BARBARA': 'SantaBarbara',\n",
    "    'SANTA CLARA': 'SantaClara',\n",
    "    'SANTA CRUZ': 'SantaCruz',\n",
    "    'SISKIYOU': 'Siskiyou',\n",
    "    'SOLANO': 'Solano',\n",
    "    'SONOMA': 'Sonoma',\n",
    "    'STANISLAUS': 'Stanislaus',\n",
    "    'SUTTER': 'Sutter',\n",
    "    'TEHAMA': 'Tehama',\n",
    "    'TULARE': 'Tulare',\n",
    "    'TUOLUMNE': 'Tuolumne',\n",
    "    'VENTURA': 'Ventura',\n",
    "    'YOLO': 'Yolo',\n",
    "    'YUBA': 'Yuba',\n",
    "    'KINGS': 'Kings'\n",
    "})\n",
    "print(vf['County'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valley Fever df is done needing to be cleaned, now it is time to clean the weather df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alameda' 'Amador' 'Berkeley' 'Butte' 'Calaveras' 'Colusa' 'ContraCosta'\n",
      " 'ElDorado' 'Fresno' 'Humboldt' 'Imperial' 'Kern' 'Lassen' 'LongBeach'\n",
      " 'Madera' 'Marin' 'Mendocino' 'Merced' 'Monterey' 'Napa' 'Nevada' 'Orange'\n",
      " 'Pasadena' 'Placer' 'Riverside' 'Sacramento' 'SanBenito' 'SanBernardino'\n",
      " 'SanDiego' 'SanFrancisco' 'SanJoaquin' 'SanLuisObispo' 'SanMateo'\n",
      " 'SantaBarbara' 'SantaClara' 'SantaCruz' 'Siskiyou' 'Solano' 'Sonoma'\n",
      " 'Stanislaus' 'Sutter' 'Tehama' 'Tulare' 'Tuolumne' 'Ventura' 'Yolo'\n",
      " 'Yuba' 'Kings']\n"
     ]
    }
   ],
   "source": [
    "# int this version i desited to keep more of the values except the ones below\n",
    "col_to_drop = ['sea_level', 'grnd_level', 'dt', 'weather_icon', 'timezone', 'lat', 'lon']\n",
    "wf = wf.drop(col_to_drop, axis=1)\n",
    "\n",
    "# create a datetime colummn for mthe dt_iso\n",
    "wf['dt_iso'] = wf['dt_iso'].str.replace(' UTC', '')\n",
    "wf['date'] = pd.to_datetime(wf['dt_iso'], format='%Y-%m-%d %H:%M:%S %z', utc=True)\n",
    "wf = wf.drop('dt_iso', axis=1)\n",
    "\n",
    "#relabell all the columns for better appearance and readability\n",
    "wf = wf.rename(columns={\n",
    "    'city_name': 'County',\n",
    "    'temp': 'Temp',\n",
    "    'visibility': 'Vis',\n",
    "    'dew_point': 'Dewpt',\n",
    "    'feels_like': 'Feels',\n",
    "    'temp_min': 'Tmin',\n",
    "    'temp_max': 'Tmax',\n",
    "    'pressure': 'Pres',\n",
    "    'humidity': 'Humid',\n",
    "    'wind_speed': 'Windsp',\n",
    "    'wind_deg': 'Windir',\n",
    "    'clouds_all': 'Clouds',\n",
    "    'weather_id': 'Wthrid',\n",
    "    'weather_main': 'Wthrmain',\n",
    "    'weather_description': 'Wthrdesc',\n",
    "    'rain_1h' : 'Rain1H',\n",
    "    'rain_3h' : 'Rain3H',\n",
    "    'snow_1h' : 'Snow1h',\n",
    "    'snow_3h' : 'Snow3N',\n",
    "    'wind_gust' : 'WindGust',\n",
    "    'date' : 'Date',\n",
    "})\n",
    "\n",
    "\n",
    "# Relabel all the couties \n",
    "wf['County'] = wf['County'].replace({\n",
    "    'Alameda County': 'Alameda',\n",
    "    'Amador County': 'Amador',\n",
    "    'Berkeley': 'Berkeley',\n",
    "    'Butte Valley': 'Butte',\n",
    "    'Calaveras County': 'Calaveras',\n",
    "    'Colusa County': 'Colusa',\n",
    "    'Contra Costa County': 'ContraCosta',\n",
    "    'El Dorado County': 'ElDorado',\n",
    "    'Fresno County': 'Fresno',\n",
    "    'Humboldt County': 'Humboldt',\n",
    "    'Imperial County': 'Imperial',\n",
    "    'Kern County': 'Kern',\n",
    "    'Lassen County': 'Lassen',\n",
    "    'Long Beach': 'LongBeach',\n",
    "    'Madera County': 'Madera',\n",
    "    'Marin County': 'Marin',\n",
    "    'Mendocino County': 'Mendocino',\n",
    "    'Merced County': 'Merced',\n",
    "    'Monterey County': 'Monterey',\n",
    "    'Napa County': 'Napa',\n",
    "    'Nevada County': 'Nevada',\n",
    "    'Orange County': 'Orange',\n",
    "    'Pasadena': 'Pasadena',\n",
    "    'Placer County': 'Placer',\n",
    "    'Riverside County': 'Riverside',\n",
    "    'Sacramento County': 'Sacramento',\n",
    "    'San Benito County': 'SanBenito',\n",
    "    'San Bernardino County': 'SanBernardino',\n",
    "    'San Diego County': 'SanDiego',\n",
    "    'San Francisco County': 'SanFrancisco',\n",
    "    'San Joaquin County': 'SanJoaquin',\n",
    "    'San Luis Obispo County': 'SanLuisObispo',\n",
    "    'San Mateo County': 'SanMateo',\n",
    "    'Santa Barbara County': 'SantaBarbara',\n",
    "    'Santa Clara County': 'SantaClara',\n",
    "    'Santa Cruz County': 'SantaCruz',\n",
    "    'Siskiyou County': 'Siskiyou',\n",
    "    'Solano County': 'Solano',\n",
    "    'Sonoma County': 'Sonoma',\n",
    "    'Stanislaus County': 'Stanislaus',\n",
    "    'Sutter County': 'Sutter',\n",
    "    'Tehama County': 'Tehama',\n",
    "    'Tulare County': 'Tulare',\n",
    "    'Tuolumne County': 'Tuolumne',\n",
    "    'Ventura County': 'Ventura',\n",
    "    'Yolo County': 'Yolo',\n",
    "    'Yuba County': 'Yuba',\n",
    "    'Kings County': 'Kings'\n",
    "})\n",
    "print(wf['County'].unique())\n",
    "\n",
    "#encode the 2 columnt that contrain string values\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "wf['Wthrmain'] = encoder.fit_transform(wf['Wthrmain'])\n",
    "wf['Wthrdesc'] = encoder.fit_transform(wf['Wthrdesc'])\n",
    "\n",
    "# i made the weather start in 2000 because the output for 2001 of the rates will contain data from september 2000 to august 2001\n",
    "wf = wf.loc[wf['Date'].dt.year >= 2000]\n",
    "wf = wf.loc[wf['Date'].dt.year <= 2022]\n",
    "\n",
    "#fill nan values\n",
    "wf.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf['Date'] = wf['Date'].dt.date.astype(str) + ' ' + wf['Date'].dt.hour.astype(str)\n",
    "wf['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d %H')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Vis</th>\n",
       "      <th>Dewpt</th>\n",
       "      <th>Feels</th>\n",
       "      <th>Tmin</th>\n",
       "      <th>Tmax</th>\n",
       "      <th>Pres</th>\n",
       "      <th>Humid</th>\n",
       "      <th>Windsp</th>\n",
       "      <th>...</th>\n",
       "      <th>WindGust</th>\n",
       "      <th>Rain1H</th>\n",
       "      <th>Rain3H</th>\n",
       "      <th>Snow1h</th>\n",
       "      <th>Snow3N</th>\n",
       "      <th>Clouds</th>\n",
       "      <th>Wthrid</th>\n",
       "      <th>Wthrmain</th>\n",
       "      <th>Wthrdesc</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184260</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>12.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.35</td>\n",
       "      <td>11.34</td>\n",
       "      <td>11.87</td>\n",
       "      <td>13.31</td>\n",
       "      <td>1016</td>\n",
       "      <td>62</td>\n",
       "      <td>2.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43</td>\n",
       "      <td>802</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2000-01-01 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184261</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>10.87</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>9.87</td>\n",
       "      <td>9.30</td>\n",
       "      <td>12.15</td>\n",
       "      <td>1017</td>\n",
       "      <td>71</td>\n",
       "      <td>4.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>804</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2000-01-01 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184262</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>10.18</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.95</td>\n",
       "      <td>9.21</td>\n",
       "      <td>8.30</td>\n",
       "      <td>11.66</td>\n",
       "      <td>1017</td>\n",
       "      <td>75</td>\n",
       "      <td>5.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>804</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2000-01-01 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184263</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>7.26</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>4.58</td>\n",
       "      <td>5.40</td>\n",
       "      <td>8.98</td>\n",
       "      <td>1018</td>\n",
       "      <td>75</td>\n",
       "      <td>4.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>804</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2000-01-01 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184264</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>6.84</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2.72</td>\n",
       "      <td>4.65</td>\n",
       "      <td>5.20</td>\n",
       "      <td>9.01</td>\n",
       "      <td>1018</td>\n",
       "      <td>75</td>\n",
       "      <td>3.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>804</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2000-01-01 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         County   Temp      Vis  Dewpt  Feels   Tmin   Tmax  Pres  Humid  \\\n",
       "184260  Alameda  12.42      0.0   5.35  11.34  11.87  13.31  1016     62   \n",
       "184261  Alameda  10.87  10000.0   5.83   9.87   9.30  12.15  1017     71   \n",
       "184262  Alameda  10.18  10000.0   5.95   9.21   8.30  11.66  1017     75   \n",
       "184263  Alameda   7.26  10000.0   3.13   4.58   5.40   8.98  1018     75   \n",
       "184264  Alameda   6.84  10000.0   2.72   4.65   5.20   9.01  1018     75   \n",
       "\n",
       "        Windsp  ...  WindGust  Rain1H  Rain3H  Snow1h  Snow3N  Clouds  Wthrid  \\\n",
       "184260    2.71  ...       0.0     0.0     0.0     0.0     0.0      43     802   \n",
       "184261    4.60  ...       0.0     0.0     0.0     0.0     0.0     100     804   \n",
       "184262    5.70  ...       0.0     0.0     0.0     0.0     0.0     100     804   \n",
       "184263    4.10  ...       0.0     0.0     0.0     0.0     0.0     100     804   \n",
       "184264    3.10  ...       0.0     0.0     0.0     0.0     0.0     100     804   \n",
       "\n",
       "        Wthrmain  Wthrdesc          Date  \n",
       "184260         1        27  2000-01-01 0  \n",
       "184261         1        19  2000-01-01 1  \n",
       "184262         1        19  2000-01-01 2  \n",
       "184263         1        19  2000-01-01 3  \n",
       "184264         1        19  2000-01-01 4  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that both datasets are clean we will create a single combined dataset from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'str' and 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m end_date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp(year\u001b[38;5;241m=\u001b[39myear \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, month\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, day\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m31\u001b[39m,)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#wf for that timeframe\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m yearly_data \u001b[38;5;241m=\u001b[39m wf[(\u001b[43mwf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m) \u001b[38;5;241m&\u001b[39m (wf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m end_date)]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#loops through each county for that year and pairs it up with the cases for that county \u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m county, group \u001b[38;5;129;01min\u001b[39;00m yearly_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCounty\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m#the rate for the counnty currently on\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/valley_fever/lib/python3.8/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/valley_fever/lib/python3.8/site-packages/pandas/core/arraylike.py:62\u001b[0m, in \u001b[0;36mOpsMixin.__ge__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ge__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ge__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mge\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/valley_fever/lib/python3.8/site-packages/pandas/core/series.py:6243\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6240\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   6242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 6243\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/valley_fever/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:287\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 287\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/valley_fever/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:75\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/valley_fever/lib/python3.8/site-packages/pandas/_libs/ops.pyx:107\u001b[0m, in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'str' and 'Timestamp'"
     ]
    }
   ],
   "source": [
    "#these will be temporarya for creating the data into the shape that will go into the tensors\n",
    "x_list = []\n",
    "y_list = []\n",
    "\n",
    "hours_per_year = 24 * 365\n",
    "\n",
    "#used for data normalization\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#outer loop ranges over the years to create a date for filtering through the wf\n",
    "for year in range(2000, 2022):\n",
    "    #start if on sept 1 and end is on aug 31 the following year\n",
    "    start_date = pd.Timestamp(year=year, month=9, day=1,)\n",
    "    end_date = pd.Timestamp(year=year + 1, month=8, day=31,)\n",
    "\n",
    "\n",
    "    #wf for that timeframe\n",
    "    yearly_data = wf[(wf['Date'] >= start_date) & (wf['Date'] <= end_date)]\n",
    "\n",
    "    #loops through each county for that year and pairs it up with the cases for that county \n",
    "    for county, group in yearly_data.groupby('County'):\n",
    "\n",
    "        #the rate for the counnty currently on\n",
    "        rate = vf[(vf['County'] == county) & (vf['Year'] == end_date.year)]['Cases']\n",
    "        #checks for missing values\n",
    "        if not rate.empty:\n",
    "            # both are objects and would also not add to learing the weather parameters so we drop them from thoe dataset\n",
    "            group = group.drop(['County', 'Date'], axis=1)  \n",
    "\n",
    "            #ensures that there is the correct amont of instances in the group            \n",
    "            if group.shape[0] >= hours_per_year:\n",
    "                #slices the data so there is no extra\n",
    "                group = group.iloc[:hours_per_year]\n",
    "                #normalizes the data\n",
    "                scaled = scaler.fit_transform(group)\n",
    "                group = pd.DataFrame(scaled, columns=group.columns)\n",
    "\n",
    "                #middlestep for converting to torch tensors\n",
    "                x_arr = group.values\n",
    "                y_arr = rate.values[0]  \n",
    "                #convert the wf values to a torch tensor then psh it to the list\n",
    "                x_list.append(torch.from_numpy(x_arr.astype(np.float32)))\n",
    "                y_list.append(torch.tensor(y_arr, dtype=torch.float32))\n",
    "\n",
    "#converts the list into a torch tensor\n",
    "x_tensor = torch.stack(x_list, dim=0)\n",
    "y_tensor = torch.stack(y_list, dim=0) \n",
    "\n",
    "\n",
    "print(f'X Shape: {x_tensor.shape}')\n",
    "print(f'Y Shape: {y_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_input_noise(X, noise_level=0.01):\n",
    "    noise = torch.randn(X.size()) * noise_level\n",
    "    return X + noise\n",
    "\n",
    "x_augmented = add_input_noise(x_tensor)\n",
    "x_combined = torch.cat([x_tensor, x_augmented], dim=0)\n",
    "y_combined = torch.cat([y_tensor, y_tensor], dim=0)\n",
    "\n",
    "x_augmented_second = add_input_noise(x_combined, 0.001)\n",
    "x_combined_final = torch.cat([x_combined, x_augmented_second], dim=0)\n",
    "y_combined_final = torch.cat([y_combined, y_combined], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##aggredate the dataset so they will be smaller sequence lengths\n",
    "x = x_combined_final.view(4224,365,24,13)\n",
    "\n",
    "x = x.mean(dim=2)\n",
    "print(x.shape)\n",
    "print(y_combined_final.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valley_fever",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
