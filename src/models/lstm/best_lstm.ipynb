{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " * @file fine_search.py\n",
    " * @author Leif Huender\n",
    " * @brief \n",
    " * @version 0.1\n",
    " * @date 2024-06-13\n",
    " * This script runs a fine search narrowing down further the best performant model on a search space of 352 models \n",
    " * @copyright Copyright (c) 2024 Leif Huender\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " * \n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " * \n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "\"\"\"\n",
    "\n",
    "import lstm\n",
    "import torch\n",
    "import plotly\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\n",
      "---------\n",
      "Train Loss RMSE: 289.5264564023874, Validation Loss RMSE: 139.48220110045628\n",
      "\n",
      "Epoch: 2/100\n",
      "---------\n",
      "Train Loss RMSE: 287.92893388338155, Validation Loss RMSE: 136.34371821638985\n",
      "\n",
      "Epoch: 3/100\n",
      "---------\n",
      "Train Loss RMSE: 288.32619343088083, Validation Loss RMSE: 138.51910819436046\n",
      "\n",
      "Epoch: 4/100\n",
      "---------\n",
      "Train Loss RMSE: 287.93211921730676, Validation Loss RMSE: 103.31949934698919\n",
      "\n",
      "Epoch: 5/100\n",
      "---------\n",
      "Train Loss RMSE: 283.1783927472261, Validation Loss RMSE: 142.430250799377\n",
      "\n",
      "Epoch: 6/100\n",
      "---------\n",
      "Train Loss RMSE: 281.60943850744576, Validation Loss RMSE: 133.98978373740326\n",
      "\n",
      "Epoch: 7/100\n",
      "---------\n",
      "Train Loss RMSE: 276.946527045703, Validation Loss RMSE: 152.60717129436856\n",
      "\n",
      "Epoch: 8/100\n",
      "---------\n",
      "Train Loss RMSE: 270.7905172173636, Validation Loss RMSE: 131.62426038862122\n",
      "\n",
      "Epoch: 9/100\n",
      "---------\n",
      "Train Loss RMSE: 280.60648374257516, Validation Loss RMSE: 136.94628878046382\n",
      "\n",
      "Epoch: 10/100\n",
      "---------\n",
      "Train Loss RMSE: 270.4463264691871, Validation Loss RMSE: 139.28982210131372\n",
      "\n",
      "Epoch: 11/100\n",
      "---------\n",
      "Train Loss RMSE: 275.5212306675792, Validation Loss RMSE: 137.47049754515513\n",
      "\n",
      "Epoch: 12/100\n",
      "---------\n",
      "Train Loss RMSE: 263.8531826518442, Validation Loss RMSE: 149.65350340550992\n",
      "\n",
      "Epoch: 13/100\n",
      "---------\n",
      "Train Loss RMSE: 258.15918304046, Validation Loss RMSE: 172.90100793495068\n",
      "\n",
      "Epoch: 14/100\n",
      "---------\n",
      "Train Loss RMSE: 252.63983388223807, Validation Loss RMSE: 70.98303535770889\n",
      "\n",
      "Epoch: 15/100\n",
      "---------\n",
      "Train Loss RMSE: 272.96763670004344, Validation Loss RMSE: 143.86624842722298\n",
      "\n",
      "Epoch: 16/100\n",
      "---------\n",
      "Train Loss RMSE: 261.7487733879408, Validation Loss RMSE: 131.04960776295448\n",
      "\n",
      "Epoch: 17/100\n",
      "---------\n",
      "Train Loss RMSE: 270.1776803859669, Validation Loss RMSE: 131.99305290667763\n",
      "\n",
      "Epoch: 18/100\n",
      "---------\n",
      "Train Loss RMSE: 247.36560500987449, Validation Loss RMSE: 126.54639943885208\n",
      "\n",
      "Epoch: 19/100\n",
      "---------\n",
      "Train Loss RMSE: 239.90934002501444, Validation Loss RMSE: 129.53076866805927\n",
      "\n",
      "Epoch: 20/100\n",
      "---------\n",
      "Train Loss RMSE: 225.55062854795835, Validation Loss RMSE: 130.1860588239362\n",
      "\n",
      "Epoch: 21/100\n",
      "---------\n",
      "Train Loss RMSE: 203.61614689166765, Validation Loss RMSE: 206.88149595635812\n",
      "\n",
      "Epoch: 22/100\n",
      "---------\n",
      "Train Loss RMSE: 260.8288501931771, Validation Loss RMSE: 137.31838458530302\n",
      "\n",
      "Epoch: 23/100\n",
      "---------\n",
      "Train Loss RMSE: 263.77040602622327, Validation Loss RMSE: 144.36016182881684\n",
      "\n",
      "Epoch: 24/100\n",
      "---------\n",
      "Train Loss RMSE: 272.1688575268679, Validation Loss RMSE: 101.88118271116114\n",
      "\n",
      "Epoch: 25/100\n",
      "---------\n",
      "Train Loss RMSE: 260.4015152586397, Validation Loss RMSE: 136.34177917832713\n",
      "\n",
      "Epoch: 26/100\n",
      "---------\n",
      "Train Loss RMSE: 240.37840237495737, Validation Loss RMSE: 193.67048771689505\n",
      "\n",
      "Epoch: 27/100\n",
      "---------\n",
      "Train Loss RMSE: 223.8314675067749, Validation Loss RMSE: 133.06817095969492\n",
      "\n",
      "Epoch: 28/100\n",
      "---------\n",
      "Train Loss RMSE: 273.79914185759804, Validation Loss RMSE: 128.2660956144674\n",
      "\n",
      "Epoch: 29/100\n",
      "---------\n",
      "Train Loss RMSE: 249.73499667890007, Validation Loss RMSE: 141.55775292123485\n",
      "\n",
      "Epoch: 30/100\n",
      "---------\n",
      "Train Loss RMSE: 242.5623277627277, Validation Loss RMSE: 131.00997677151108\n",
      "\n",
      "Epoch: 31/100\n",
      "---------\n",
      "Train Loss RMSE: 263.29149087695356, Validation Loss RMSE: 137.45944536878415\n",
      "\n",
      "Epoch: 32/100\n",
      "---------\n",
      "Train Loss RMSE: 283.7944753425953, Validation Loss RMSE: 131.86650779825123\n",
      "\n",
      "Epoch: 33/100\n",
      "---------\n",
      "Train Loss RMSE: 261.72286917151945, Validation Loss RMSE: 127.48105854630302\n",
      "\n",
      "Epoch: 34/100\n",
      "---------\n",
      "Train Loss RMSE: 229.04416070432467, Validation Loss RMSE: 107.55590672431273\n",
      "\n",
      "Epoch: 35/100\n",
      "---------\n",
      "Train Loss RMSE: 213.05666714971514, Validation Loss RMSE: 119.97315398964327\n",
      "\n",
      "Epoch: 36/100\n",
      "---------\n",
      "Train Loss RMSE: 208.62772442279044, Validation Loss RMSE: 135.26582805084678\n",
      "\n",
      "Epoch: 37/100\n",
      "---------\n",
      "Train Loss RMSE: 205.96247036194262, Validation Loss RMSE: 129.70180455748775\n",
      "\n",
      "Epoch: 38/100\n",
      "---------\n",
      "Train Loss RMSE: 196.7831203095114, Validation Loss RMSE: 76.756208237052\n",
      "\n",
      "Epoch: 39/100\n",
      "---------\n",
      "Train Loss RMSE: 187.26978115577398, Validation Loss RMSE: 177.11657358826824\n",
      "\n",
      "Epoch: 40/100\n",
      "---------\n",
      "Train Loss RMSE: 210.8288038846771, Validation Loss RMSE: 136.03798818166794\n",
      "\n",
      "Epoch: 41/100\n",
      "---------\n",
      "Train Loss RMSE: 283.77627789252364, Validation Loss RMSE: 85.69740395102592\n",
      "\n",
      "Epoch: 42/100\n",
      "---------\n",
      "Train Loss RMSE: 179.6366608704434, Validation Loss RMSE: 90.71221423020648\n",
      "\n",
      "Epoch: 43/100\n",
      "---------\n",
      "Train Loss RMSE: 169.36258568100956, Validation Loss RMSE: 150.87134209396552\n",
      "\n",
      "Epoch: 44/100\n",
      "---------\n",
      "Train Loss RMSE: 159.01073248261815, Validation Loss RMSE: 142.39255775120301\n",
      "\n",
      "Epoch: 45/100\n",
      "---------\n",
      "Train Loss RMSE: 219.52383666033077, Validation Loss RMSE: 112.91640276625834\n",
      "\n",
      "Epoch: 46/100\n",
      "---------\n",
      "Train Loss RMSE: 159.38294802679434, Validation Loss RMSE: 167.27011548517515\n",
      "\n",
      "Epoch: 47/100\n",
      "---------\n",
      "Train Loss RMSE: 161.0188510535832, Validation Loss RMSE: 167.54179894740074\n",
      "\n",
      "Epoch: 48/100\n",
      "---------\n",
      "Train Loss RMSE: 147.98631223400082, Validation Loss RMSE: 74.61903487858133\n",
      "\n",
      "Epoch: 49/100\n",
      "---------\n",
      "Train Loss RMSE: 150.39579209407472, Validation Loss RMSE: 153.37364339189668\n",
      "\n",
      "Epoch: 50/100\n",
      "---------\n",
      "Train Loss RMSE: 163.76748977917723, Validation Loss RMSE: 215.8133303452025\n",
      "\n",
      "Epoch: 51/100\n",
      "---------\n",
      "Train Loss RMSE: 157.3175688613123, Validation Loss RMSE: 189.22183207388738\n",
      "\n",
      "Epoch: 52/100\n",
      "---------\n",
      "Train Loss RMSE: 156.22168099779145, Validation Loss RMSE: 173.43186118367296\n",
      "\n",
      "Epoch: 53/100\n",
      "---------\n",
      "Train Loss RMSE: 138.34796584561886, Validation Loss RMSE: 189.0294528194036\n",
      "\n",
      "Epoch: 54/100\n",
      "---------\n",
      "Train Loss RMSE: 136.11244259723014, Validation Loss RMSE: 202.5554979168132\n",
      "\n",
      "Epoch: 55/100\n",
      "---------\n",
      "Train Loss RMSE: 132.8917663382003, Validation Loss RMSE: 81.2071299913116\n",
      "\n",
      "Epoch: 56/100\n",
      "---------\n",
      "Train Loss RMSE: 168.6008195343684, Validation Loss RMSE: 121.68324169668745\n",
      "\n",
      "Epoch: 57/100\n",
      "---------\n",
      "Train Loss RMSE: 125.20358903320775, Validation Loss RMSE: 219.07775056133752\n",
      "\n",
      "Epoch: 58/100\n",
      "---------\n",
      "Train Loss RMSE: 69.97440003452382, Validation Loss RMSE: 102.42259010047844\n",
      "\n",
      "Epoch: 59/100\n",
      "---------\n",
      "Train Loss RMSE: 61.62017112307513, Validation Loss RMSE: 134.41312254466462\n",
      "\n",
      "Epoch: 60/100\n",
      "---------\n",
      "Train Loss RMSE: 60.29149176727253, Validation Loss RMSE: 102.40607775294485\n",
      "\n",
      "Epoch: 61/100\n",
      "---------\n",
      "Train Loss RMSE: 58.96037247364848, Validation Loss RMSE: 174.24265320886738\n",
      "\n",
      "Epoch: 62/100\n",
      "---------\n",
      "Train Loss RMSE: 60.91238670873467, Validation Loss RMSE: 185.75681609718256\n",
      "\n",
      "Epoch: 63/100\n",
      "---------\n",
      "Train Loss RMSE: 198.52590123695438, Validation Loss RMSE: 162.46861100085417\n",
      "\n",
      "Epoch: 64/100\n",
      "---------\n",
      "Train Loss RMSE: 138.05400033450337, Validation Loss RMSE: 137.73832860888342\n",
      "\n",
      "Epoch: 65/100\n",
      "---------\n",
      "Train Loss RMSE: 65.67904385683192, Validation Loss RMSE: 146.20772250506192\n",
      "\n",
      "Epoch: 66/100\n",
      "---------\n",
      "Train Loss RMSE: 60.41531006264627, Validation Loss RMSE: 112.10792736434693\n",
      "\n",
      "Epoch: 67/100\n",
      "---------\n",
      "Train Loss RMSE: 53.12164434850352, Validation Loss RMSE: 95.60365908974225\n",
      "\n",
      "Epoch: 68/100\n",
      "---------\n",
      "Train Loss RMSE: 50.391567401310546, Validation Loss RMSE: 119.39806075318432\n",
      "\n",
      "Epoch: 69/100\n",
      "---------\n",
      "Train Loss RMSE: 88.14130235727805, Validation Loss RMSE: 105.75632697763658\n",
      "\n",
      "Epoch: 70/100\n",
      "---------\n",
      "Train Loss RMSE: 56.82959696587455, Validation Loss RMSE: 94.31665660882592\n",
      "\n",
      "Epoch: 71/100\n",
      "---------\n",
      "Train Loss RMSE: 47.667327846301255, Validation Loss RMSE: 110.8097063240626\n",
      "\n",
      "Epoch: 72/100\n",
      "---------\n",
      "Train Loss RMSE: 49.71623151640431, Validation Loss RMSE: 100.33780225093071\n",
      "\n",
      "Epoch: 73/100\n",
      "---------\n",
      "Train Loss RMSE: 42.72200587916521, Validation Loss RMSE: 94.207157506161\n",
      "\n",
      "Epoch: 74/100\n",
      "---------\n",
      "Train Loss RMSE: 82.78203092792808, Validation Loss RMSE: 86.06293260829905\n",
      "\n",
      "Epoch: 75/100\n",
      "---------\n",
      "Train Loss RMSE: 65.93733813379069, Validation Loss RMSE: 62.90420224172602\n",
      "\n",
      "Epoch: 76/100\n",
      "---------\n",
      "Train Loss RMSE: 56.90481713306895, Validation Loss RMSE: 83.43994905113647\n",
      "\n",
      "Epoch: 77/100\n",
      "---------\n",
      "Train Loss RMSE: 48.51644969866117, Validation Loss RMSE: 77.88878077367855\n",
      "\n",
      "Epoch: 78/100\n",
      "---------\n",
      "Train Loss RMSE: 44.76754450702749, Validation Loss RMSE: 71.23766126371794\n",
      "\n",
      "Epoch: 79/100\n",
      "---------\n",
      "Train Loss RMSE: 40.259760036767595, Validation Loss RMSE: 83.32464204351368\n",
      "\n",
      "Epoch: 80/100\n",
      "---------\n",
      "Train Loss RMSE: 42.149573207605165, Validation Loss RMSE: 100.66260639953865\n",
      "\n",
      "Epoch: 81/100\n",
      "---------\n",
      "Train Loss RMSE: 64.55411673710829, Validation Loss RMSE: 95.0142747293466\n",
      "\n",
      "Epoch: 82/100\n",
      "---------\n",
      "Train Loss RMSE: 81.7907066289165, Validation Loss RMSE: 96.85145442187645\n",
      "\n",
      "Epoch: 83/100\n",
      "---------\n",
      "Train Loss RMSE: 45.31430411352231, Validation Loss RMSE: 89.06860930252553\n",
      "\n",
      "Epoch: 84/100\n",
      "---------\n",
      "Train Loss RMSE: 33.36905075213186, Validation Loss RMSE: 92.60412214097167\n",
      "\n",
      "Epoch: 85/100\n",
      "---------\n",
      "Train Loss RMSE: 48.408138578489236, Validation Loss RMSE: 88.90397075285783\n",
      "\n",
      "Epoch: 86/100\n",
      "---------\n",
      "Train Loss RMSE: 29.682633739795566, Validation Loss RMSE: 107.19975103093174\n",
      "\n",
      "Epoch: 87/100\n",
      "---------\n",
      "Train Loss RMSE: 25.667254982201975, Validation Loss RMSE: 91.07946661175201\n",
      "\n",
      "Epoch: 88/100\n",
      "---------\n",
      "Train Loss RMSE: 153.65977536926852, Validation Loss RMSE: 127.32260704465817\n",
      "\n",
      "Epoch: 89/100\n",
      "---------\n",
      "Train Loss RMSE: 173.24096217879054, Validation Loss RMSE: 103.97623993816899\n",
      "\n",
      "Epoch: 90/100\n",
      "---------\n",
      "Train Loss RMSE: 121.9657472848826, Validation Loss RMSE: 98.75618799836671\n",
      "\n",
      "Epoch: 91/100\n",
      "---------\n",
      "Train Loss RMSE: 72.76808278657984, Validation Loss RMSE: 104.7269707540532\n",
      "\n",
      "Epoch: 92/100\n",
      "---------\n",
      "Train Loss RMSE: 68.27980766457799, Validation Loss RMSE: 93.78406981843443\n",
      "\n",
      "Epoch: 93/100\n",
      "---------\n",
      "Train Loss RMSE: 60.04667662208123, Validation Loss RMSE: 121.68703253312881\n",
      "\n",
      "Epoch: 94/100\n",
      "---------\n",
      "Train Loss RMSE: 55.6707655931811, Validation Loss RMSE: 91.1985049074999\n",
      "\n",
      "Epoch: 95/100\n",
      "---------\n",
      "Train Loss RMSE: 59.76028838397988, Validation Loss RMSE: 122.24795898730784\n",
      "\n",
      "Epoch: 96/100\n",
      "---------\n",
      "Train Loss RMSE: 50.79947631110183, Validation Loss RMSE: 127.67154704859361\n",
      "\n",
      "Epoch: 97/100\n",
      "---------\n",
      "Train Loss RMSE: 98.62764492286318, Validation Loss RMSE: 98.00141002652717\n",
      "\n",
      "Epoch: 98/100\n",
      "---------\n",
      "Train Loss RMSE: 54.5097399460006, Validation Loss RMSE: 132.72167482649547\n",
      "\n",
      "Epoch: 99/100\n",
      "---------\n",
      "Train Loss RMSE: 48.59374974675004, Validation Loss RMSE: 94.80380195043769\n",
      "\n",
      "Epoch: 100/100\n",
      "---------\n",
      "Train Loss RMSE: 44.00388909228038, Validation Loss RMSE: 106.23768138607441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load all the datasets\n",
    "train = torch.load('../../../data/cleaned/train.pt')\n",
    "val = torch.load('../../../data/cleaned/val.pt')\n",
    "test = torch.load('../../../data/cleaned/test.pt')\n",
    "\n",
    "#make them into dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train, batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val, batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test, batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "'''\n",
    "Fine Search results\n",
    "Min Train RMSE: 11.33083176851998\n",
    "Min Validation RMSE: 70.89486087741568\n",
    "{'hidden_size': 200, 'num_layers': 2, 'bias': False, 'batch_first': True, 'dropout': 0, 'bidirectional': False, 'proj_size': 0}\n",
    "'''\n",
    "\n",
    "model = lstm.LSTM(input_size=19, hidden_size=200, num_layers=2, bias=False, batch_first=True, dropout=0, bidirectional=False, proj_size=0)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "trainer = lstm.Trainer(model, train_loader, val_loader, loss_fn, optimizer)\n",
    "model, train_losses, val_losses = trainer.train(epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[289.5264564023874, 287.92893388338155, 288.32619343088083, 287.93211921730676, 283.1783927472261, 281.60943850744576, 276.946527045703, 270.7905172173636, 280.60648374257516, 270.4463264691871, 275.5212306675792, 263.8531826518442, 258.15918304046, 252.63983388223807, 272.96763670004344, 261.7487733879408, 270.1776803859669, 247.36560500987449, 239.90934002501444, 225.55062854795835, 203.61614689166765, 260.8288501931771, 263.77040602622327, 272.1688575268679, 260.4015152586397, 240.37840237495737, 223.8314675067749, 273.79914185759804, 249.73499667890007, 242.5623277627277, 263.29149087695356, 283.7944753425953, 261.72286917151945, 229.04416070432467, 213.05666714971514, 208.62772442279044, 205.96247036194262, 196.7831203095114, 187.26978115577398, 210.8288038846771, 283.77627789252364, 179.6366608704434, 169.36258568100956, 159.01073248261815, 219.52383666033077, 159.38294802679434, 161.0188510535832, 147.98631223400082, 150.39579209407472, 163.76748977917723, 157.3175688613123, 156.22168099779145, 138.34796584561886, 136.11244259723014, 132.8917663382003, 168.6008195343684, 125.20358903320775, 69.97440003452382, 61.62017112307513, 60.29149176727253, 58.96037247364848, 60.91238670873467, 198.52590123695438, 138.05400033450337, 65.67904385683192, 60.41531006264627, 53.12164434850352, 50.391567401310546, 88.14130235727805, 56.82959696587455, 47.667327846301255, 49.71623151640431, 42.72200587916521, 82.78203092792808, 65.93733813379069, 56.90481713306895, 48.51644969866117, 44.76754450702749, 40.259760036767595, 42.149573207605165, 64.55411673710829, 81.7907066289165, 45.31430411352231, 33.36905075213186, 48.408138578489236, 29.682633739795566, 25.667254982201975, 153.65977536926852, 173.24096217879054, 121.9657472848826, 72.76808278657984, 68.27980766457799, 60.04667662208123, 55.6707655931811, 59.76028838397988, 50.79947631110183, 98.62764492286318, 54.5097399460006, 48.59374974675004, 44.00388909228038]\n"
     ]
    }
   ],
   "source": [
    "print(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[139.48220110045628, 136.34371821638985, 138.51910819436046, 103.31949934698919, 142.430250799377, 133.98978373740326, 152.60717129436856, 131.62426038862122, 136.94628878046382, 139.28982210131372, 137.47049754515513, 149.65350340550992, 172.90100793495068, 70.98303535770889, 143.86624842722298, 131.04960776295448, 131.99305290667763, 126.54639943885208, 129.53076866805927, 130.1860588239362, 206.88149595635812, 137.31838458530302, 144.36016182881684, 101.88118271116114, 136.34177917832713, 193.67048771689505, 133.06817095969492, 128.2660956144674, 141.55775292123485, 131.00997677151108, 137.45944536878415, 131.86650779825123, 127.48105854630302, 107.55590672431273, 119.97315398964327, 135.26582805084678, 129.70180455748775, 76.756208237052, 177.11657358826824, 136.03798818166794, 85.69740395102592, 90.71221423020648, 150.87134209396552, 142.39255775120301, 112.91640276625834, 167.27011548517515, 167.54179894740074, 74.61903487858133, 153.37364339189668, 215.8133303452025, 189.22183207388738, 173.43186118367296, 189.0294528194036, 202.5554979168132, 81.2071299913116, 121.68324169668745, 219.07775056133752, 102.42259010047844, 134.41312254466462, 102.40607775294485, 174.24265320886738, 185.75681609718256, 162.46861100085417, 137.73832860888342, 146.20772250506192, 112.10792736434693, 95.60365908974225, 119.39806075318432, 105.75632697763658, 94.31665660882592, 110.8097063240626, 100.33780225093071, 94.207157506161, 86.06293260829905, 62.90420224172602, 83.43994905113647, 77.88878077367855, 71.23766126371794, 83.32464204351368, 100.66260639953865, 95.0142747293466, 96.85145442187645, 89.06860930252553, 92.60412214097167, 88.90397075285783, 107.19975103093174, 91.07946661175201, 127.32260704465817, 103.97623993816899, 98.75618799836671, 104.7269707540532, 93.78406981843443, 121.68703253312881, 91.1985049074999, 122.24795898730784, 127.67154704859361, 98.00141002652717, 132.72167482649547, 94.80380195043769, 106.23768138607441]\n"
     ]
    }
   ],
   "source": [
    "print(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valley_fever",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
