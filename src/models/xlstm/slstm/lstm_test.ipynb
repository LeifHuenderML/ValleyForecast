{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.xlstm.slstm.slstm as slstm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, epochs, loader, loss_fn, optim):\n",
    "    losses = []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        num_batches = len(loader)\n",
    "        total_loss = 0\n",
    "        for x, y in loader:\n",
    "            x, y = x.to('cuda'), y.to('cuda')\n",
    "            output = model(x)\n",
    "            loss = loss_fn(output, y)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss/num_batches\n",
    "        avg_loss = np.sqrt(avg_loss)\n",
    "        losses.append(avg_loss)\n",
    "        print(f'Epoch {epoch} RMSE Loss: {avg_loss}')\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.load('../../../../data/cleaned/train.pt')\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train, batch_size, shuffle=True, drop_last=True)\n",
    "model = slstm.LSTMv2(input_size=19, hidden_size=200)\n",
    "model.to('cuda')\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optim = torch.optim.Adam(params=model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 RMSE Loss: 289.50072597636654\n",
      "Epoch 2 RMSE Loss: 289.22624382542483\n",
      "Epoch 3 RMSE Loss: 289.01990899542477\n",
      "Epoch 4 RMSE Loss: 288.86710208380975\n",
      "Epoch 5 RMSE Loss: 289.16718359217174\n",
      "Epoch 6 RMSE Loss: 289.11624827678173\n",
      "Epoch 7 RMSE Loss: 289.08214614063195\n",
      "Epoch 8 RMSE Loss: 289.2245024064565\n",
      "Epoch 9 RMSE Loss: 288.9708901687688\n",
      "Epoch 10 RMSE Loss: 288.67831187215836\n",
      "Epoch 11 RMSE Loss: 288.5552133386419\n",
      "Epoch 12 RMSE Loss: 284.3939644625091\n",
      "Epoch 13 RMSE Loss: 283.29914835831926\n",
      "Epoch 14 RMSE Loss: 282.154568427457\n",
      "Epoch 15 RMSE Loss: 280.19619069039976\n",
      "Epoch 16 RMSE Loss: 281.617091086267\n",
      "Epoch 17 RMSE Loss: 277.2751046870622\n",
      "Epoch 18 RMSE Loss: 274.93009580597413\n",
      "Epoch 19 RMSE Loss: 270.18555517725343\n",
      "Epoch 20 RMSE Loss: 267.4481452424674\n",
      "Epoch 21 RMSE Loss: 250.40582769437705\n",
      "Epoch 22 RMSE Loss: 277.70687284174\n",
      "Epoch 23 RMSE Loss: 256.34974737936597\n",
      "Epoch 24 RMSE Loss: 259.8689960687143\n",
      "Epoch 25 RMSE Loss: 230.70294877855625\n",
      "Epoch 26 RMSE Loss: 276.2914009126857\n",
      "Epoch 27 RMSE Loss: 278.42946348199183\n",
      "Epoch 28 RMSE Loss: 287.6475019554841\n",
      "Epoch 29 RMSE Loss: 288.270097528872\n",
      "Epoch 30 RMSE Loss: 251.14775412877182\n",
      "Epoch 31 RMSE Loss: 198.53571566758527\n",
      "Epoch 32 RMSE Loss: 208.01704383391572\n",
      "Epoch 33 RMSE Loss: 200.36423607134273\n",
      "Epoch 34 RMSE Loss: 179.9844638324207\n",
      "Epoch 35 RMSE Loss: 140.39225364838504\n",
      "Epoch 36 RMSE Loss: 224.8350993159289\n",
      "Epoch 37 RMSE Loss: 187.94149954657536\n",
      "Epoch 38 RMSE Loss: 172.78199562062832\n",
      "Epoch 39 RMSE Loss: 154.09310834153814\n",
      "Epoch 40 RMSE Loss: 152.99453113307112\n",
      "Epoch 41 RMSE Loss: 159.73517218872956\n",
      "Epoch 42 RMSE Loss: 145.68805945322217\n",
      "Epoch 43 RMSE Loss: 187.38193682144842\n",
      "Epoch 44 RMSE Loss: 162.46143604393072\n",
      "Epoch 45 RMSE Loss: 141.2575896854306\n",
      "Epoch 46 RMSE Loss: 141.316518193894\n",
      "Epoch 47 RMSE Loss: 132.11067283718077\n",
      "Epoch 48 RMSE Loss: 165.58186887422906\n",
      "Epoch 49 RMSE Loss: 138.5796186395292\n",
      "Epoch 50 RMSE Loss: 85.1789323395486\n",
      "Epoch 51 RMSE Loss: 77.93074306747936\n",
      "Epoch 52 RMSE Loss: 87.39482692823077\n",
      "Epoch 53 RMSE Loss: 80.84339624105412\n",
      "Epoch 54 RMSE Loss: 75.15593702192152\n",
      "Epoch 55 RMSE Loss: 76.7035199354711\n",
      "Epoch 56 RMSE Loss: 139.75834691346256\n",
      "Epoch 57 RMSE Loss: 115.82340412168108\n",
      "Epoch 58 RMSE Loss: 72.88362116387717\n",
      "Epoch 59 RMSE Loss: 77.67951938514491\n",
      "Epoch 60 RMSE Loss: 69.87286025248135\n",
      "Epoch 61 RMSE Loss: 66.51110750813642\n",
      "Epoch 62 RMSE Loss: 63.72908581188696\n",
      "Epoch 63 RMSE Loss: 113.48725097297972\n",
      "Epoch 64 RMSE Loss: 61.37573055987762\n",
      "Epoch 65 RMSE Loss: 63.8693771269518\n",
      "Epoch 66 RMSE Loss: 103.86797607427863\n",
      "Epoch 67 RMSE Loss: 59.434200696541545\n",
      "Epoch 68 RMSE Loss: 59.689069961465464\n",
      "Epoch 69 RMSE Loss: 66.59865425571975\n",
      "Epoch 70 RMSE Loss: 112.47019618515918\n",
      "Epoch 71 RMSE Loss: 70.48166012930918\n",
      "Epoch 72 RMSE Loss: 74.03338993104902\n",
      "Epoch 73 RMSE Loss: 59.072100408556146\n",
      "Epoch 74 RMSE Loss: 68.50794846665146\n",
      "Epoch 75 RMSE Loss: 78.50604948967633\n",
      "Epoch 76 RMSE Loss: 64.1946990341378\n",
      "Epoch 77 RMSE Loss: 56.61026806417487\n",
      "Epoch 78 RMSE Loss: 60.56992703368618\n",
      "Epoch 79 RMSE Loss: 48.98749550013041\n",
      "Epoch 80 RMSE Loss: 48.35530540829427\n",
      "Epoch 81 RMSE Loss: 77.96627957486278\n",
      "Epoch 82 RMSE Loss: 98.43012923413522\n",
      "Epoch 83 RMSE Loss: 43.61331627767454\n",
      "Epoch 84 RMSE Loss: 41.34716271429349\n",
      "Epoch 85 RMSE Loss: 74.78832040629987\n",
      "Epoch 86 RMSE Loss: 67.34774345199904\n",
      "Epoch 87 RMSE Loss: 51.487933991439576\n",
      "Epoch 88 RMSE Loss: 45.35299518337026\n",
      "Epoch 89 RMSE Loss: 47.21896825180558\n",
      "Epoch 90 RMSE Loss: 36.76450396453364\n",
      "Epoch 91 RMSE Loss: 31.445132319847094\n",
      "Epoch 92 RMSE Loss: 31.687228768667513\n",
      "Epoch 93 RMSE Loss: 31.70139226021533\n",
      "Epoch 94 RMSE Loss: 71.38555244979165\n",
      "Epoch 95 RMSE Loss: 37.38376489690554\n",
      "Epoch 96 RMSE Loss: 30.124305747495697\n",
      "Epoch 97 RMSE Loss: 29.49676449208035\n"
     ]
    }
   ],
   "source": [
    "losses = trainer(model, 100, train_loader, loss_fn, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valley_fever",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
